---
layout: post
title: "Project 6 (Random Trees) - Predicting IMDb 250 Ratings
comments: false
description: "Project 6 from GA"
keywords: "data science, student, analysis"
---

For this week, the goal was to be able to predict the rating of a movie on the IMDb top 250 movie list, and to identify which factors were the most salient in being able to predict a rating.

---

## The Data Source and Methodology

#### Target Variable

The target variable for this exercise was the IMDb rating, which was treated as a continous variable. 

Typically, the rating ranges from 0.0 to 10.0, but given that we were focused on the top 250, the minimum in our dataset was 8.0, and the maximum was 9.3.

#### Features

Features were extracted from available information each movies' IMDb age. The following were chosen based off of their respective assumptions:

- Number of Votes for Rating: assume that these were positively correlated. 
- Plot Keywords (pulled all keywords as listed by IMDb): assume that there were specific topics that were of more interest to determine a higher rating. 
- Director (could be 1 or 2): assume that specific directors were more likely to create higher ranked movies.
- Top 3 Stars (Actors/Actresses): assume that specific actors/actresses were likely to star in higher ranked movies.
- Year of Release: assume that the age of the movie mattered - classic movies, for example, might have greater credibility, or more recent movies might be fresher, and thus ranked higher.
- Month of Release: assume seasonality mattered (e.g. summer blockbusters or movies closer to awards season).
- Movie Rating: assume that movies that weren't rated R were more likely to be ranked lower.
- Duration of Movie: assume that length could matter.

It is worth noting that through initial exploration, Number of Votes appeared to be the most correlated compared to each of the other features:

![num_votes](http://yoyoyokatty.github.io/images_kl/project6-imdb/num_votes.png)

For text-based features such as Stars, Keywords and Directors, each subset was relatively large. There were 584 individual Stars, 1067 Keywords and 167 Directors. So, although there were clear "winners" that were more likely to be in the 250 list (ex: only 5 directors with 7 movies in the list), the length of these features were predicted to have been heavily diluted.

---

## The Final Model

Various tree-based methods were used to develop the model including Decision Trees, Random Forests, Extra Trees, Gradient Boost, Bagged Decision Trees and Extra Trees. 

Given apprehensions around the total volume of end features (which was close to 1900), various feature selection models were tested as well. This included using SelectKBest to identify the top features, and manually extracting features (e.g. plot keywords were left off in one iteration).

The best performing model based off a R-squared of .72 was the Gradient Boost model, using all features:

![model_predict](http://yoyoyokatty.github.io/images_kl/project6-imdb/model_predict.png)

---

### Feature Importance

Despite 1898 total features, the final model was mostly influenced by 1 key features, namely the Number of Votes (as predicted earlier):

|          Feature           | Relative Importance | 
|:--------------------------:|---------------------|
| Number of Votes            | .139                |
| Year of Release            | .075                |
| Duration                   | .037                |
| Director: Stanley Kubrick  | .029                |
| Plot Keyword: Mexican      | .028                |
| Director: Steven Spielberg | .023                |
| Director: Ridley Scott     | .022                |
| Director: Charles Chaplin  | .022                |

The fact that Number of Votes is the most salient factor could be a result of mob mentality. Perhaps when a movie is already well-rated, and with a high volume of votes, people are less likely to vote the movie down. 

The second most imoprtant feature was the Year of Release - all other features only marginally contributed to the predictability of the model. 

---

### What's Next?

This first iteration of the model performed relatively well at a .72 R-squared, however there is always room for improvement.

Further analysis could be done on refining our feature selection, including reducing plot keywords to a refined few, to reduce the number of features coming from this macro-feature, and potentially increasing the predictability of plots. 

Additional features could also be added, including scores from other sites, such as Rotten Tomatoes, or Metacritic. 
